<!DOCTYPE html>
<html>
    <head>
        <title>NLTK Sentiment Analysis Tutorial</title>
    </head>
    
    <body>
        <header>
            <h1>Introduction</h1>
            <p> Natural Language Toolkit, or NLTK, is a Python library configured to analyze natural speech data. NLTK offers a wide range of features that can easily process any body of text, such as part-of-speech tagging, tokenization, and semantic reasoning. 
                One of NLTK's most popular features is its sentiment analysis tool, VADER. VADER, also known as <b>Valence Aware Dictionary for sEntiment Reasoning</b>, uses its sentiment lexicon and a blend of grammatical rules and syntactical conventions.</p>

            <h2>How does VADER work?</h2>
            <h3>Sentiment Lexicon</h3>
                <p>A sentiment lexicon is a dictionary that maps words, phrases, and symbols and matches those to a specific emotional valence. VADER's literature further explains this process:</p>
                <blockquote> "We  begin  by  constructing  a  list  inspired  by  examiningexisting well-established  sentiment  word-banks  (LIWC, ANEW, and  GI).  To  this,  we  next  incorporate  numerous lexical  features  common  to  sentiment  expression  
                    in  microblogs, including a full list of Western-style  emoticons (for example, “:-)” denotes a “smiley face” and generally indicates  positive  sentiment),  sentiment-related  acronyms and  initialisms (e.g.,  LOL  and  WTF  are  both  
                    sentiment-laden  initialisms),  and  commonly  used  slang  with  senti-ment value (e.g., “nah”, “meh   ”and “giggly”). This processprovided us with over 9,000 lexical feature candidates. Next,  we  assessed  the  general  applicability  
                    of  each  feature  candidate  to  sentiment  expressions.  We  used  a  wisdom-of-the-crowd  (WotC)  approach  (Surowiecki,  2004) to  acquire  a  valid  point  estimate  for  the  sentiment  valence (intensity)  of  each  context-free  
                    candidate  feature.  We  collected  intensity  ratings  on  each  of  our  candidate  lexical features  from  ten  independent  human  raters  (for  a  total  of 90,000+ ratings). Features were rated on a scale from '[–4] Extremely Negative' 
                    to '[4] Extremely Positive', with allowance for '[0] Neutral (or Neither, N/A)'" (Hutto & Gilbert, 2014). </blockquote>
                <p>The image below demonstrates the methods used to create VADER. With this, you can gain a deeper understanding of how VADER came about and what kinds of data may work best for an analysis with this tool:</p>
                <figure>
                    <img src="presidential-candidate-sentiment-analysis/method.png" alt= "VADER Method Diagram">
                </figure>
        <nav>
            <ul>
                <h2>Sections</h2>
                <li><a href="#step0">Step 0: Installing and Importing Modules</a></li>
                <li><a href="#step1">Step 1: Loading in and Cleaning Up Your CSV</a></li>
                <li><a href="#step2">Step 2: Create a Speaker Dictionary</a></li>
                <li><a href="#step3">Step 3: Tokenizing and Lemmatizing</a></li>
                <li><a href="#step4">Step 4: Analyzing Your Data</a></li>
                <li><a href="#step5">Step 5: Results</a></li>
            </ul>
        </nav>

        </header>

        
        <main>
            <section id="step0">
                <h2>Step 0: Installing and Importing Modules</h2>
                <p>For step zero, you will need to start by installing and importing the necessary modules. For this particular analysis, you will need to download the following modules onto your terminal.</p>
                <pre><code>
                    pip install pandas
                    pip install nltk
                    # this code will download all of the necessary 
                    python3 -c "import nltk; [nltk.download(x) for x in ['vader_lexicon', 'stopwords', 'punkt', 'wordnet', 'omw-1.4']]"
                </pre></code>
                <p> Once you download those, you will need to also download our dataset from GitHub. Make sure you are downloading the <b>raw</b> dataset. You can do this directly in your terminal like this:</p>
                <pre><code> 
                wget https://raw.githubusercontent.com/favstats/demdebates2020/refs/heads/master/data/debates.csv
                </code></pre>
                <p> Use <code>python3</code> to import your modules like so:<p>
                    <pre><code>
                        import nltk
                        from nltk.sentiment.vader import SentimentIntensityAnalyzer
                        from nltk.corpus import stopwords
                        from nltk.tokenize import word_tokenize
                        from nltk.stem import WordNetLemmatizer
                        import re
                        import pandas as pd
                        import string
                    </code></pre>
                <p> Once everything is downloaded correctly, you are ready to head to step 1.</p>
                
            </section>

            <section id="step1">
                <h2>Step 1: Loading in and Cleaning Up Your CSV</h2>
                <p>Once you have imported all your modules and downloaded your data, it's time to load in the file.</p>
                <pre><code>
                 df = pd.read_csv('debates.csv')
                 csvcleaned = df[
                 (df['speech'] != 'NA') &
                 (df['type'] != 'Moderator') &
                 (~df['speaker'].isin(['Speaker 1:', 'Speaker 2:', 'speaker 6:', 'speaker 7:', 'speaker 8:', 'Unknown',
                                                                                                'Protester']))] \
                 .drop(columns=['background', 'gender', 'debate', 'day', 'type', 'order']
                 )
                 csvcleaned.to_csv('debate.csv', index=False)   
                </code></pre>

                <p>Let's break down each piece of the code:</p>
                <pre><code>df = pd.read_csv('debates.csv')</code></pre>
                <p>The variable "df" here stands for DataFrame, a type of document structure. These are commonly used with datasets that have rows and columns (e.g. spreadsheet, CSV, SQL table). We are essentially loading debates.csv in to the DataFrame.

                <pre><code>
                csvcleaned = df[
                (df['speech'] != 'NA') &
                (df['type'] != 'Moderator') &
                (~df['speaker'].isin(['Speaker 1:', 'Speaker 2:', 'speaker 6:', 'speaker 7:', 'speaker 8:', 'Unknown',
                'Protester']))] \
                .drop(columns=['background', 'gender', 'debate', 'day', 'type', 'order']
                )
                csvcleaned.to_csv('data.csv', index=False)
                </pre></code>
                
                <p>This serves to tell the program to remove columns we don't want ('background', 'gender', 'debate', 'day', 'type', 'order'), as well as not adding any data where the row has "NA" in the speech column or 'Speaker 1:', 'Speaker 2:', 
                'speaker 6:', 'speaker 7:', 'speaker 8:', 'Unknown',
                'Protester.' Once that is all compiled, everything in the variable 'csvcleaned' will be added in a new CSV file called 'data.csv'. Make sure to check that your data.csv file is correctly displaying the data you want. This CSV file 
                isn't actually going to be used in the code from here, but it is a great way to visualize and ensure all the data you're extracting is what you need. If you see any rows or columns that shouldn't be there, you know to go back. Once 
                you've extracted and put in the data you are looking to analyze, you can move on to the lemmatization.</p>
                
            </section>

            <section id="step2">
                <h2>Step 2: Create a Speaker Dictionary</h2>
                <p>Once you have your 'speaker' and 'speech' data into your data.csv file, you will want to create a dictionary for each candidate, complete with all the speech they uttered over all the debates. To do this, we'll use the following code:</p>
                <pre><code>
                speakerdictionary = {}
                for _, row in csvcleaned.iterrows():
                    speaker = row['speaker']
                    speech = row['speech']

                if speaker not in speakerdictionary:
                    speakerdictionary[speaker] = []
                speakerdictionary[speaker].append(speech)
                </code></pre>
                
                <p>Again, let's look at this step by step.</p>
                <pre><code>
                speakerdictionary = {}
                for _, row in csvcleaned.iterrows():
                    speaker = row['speaker']
                    speech = row['speech']
                </code></pre>
                <p>What this will do is initialize an empty dictionary called "speakerdictionary." Python will loop through each of the rows, using the .iterrows() function. .Iterrows() is a method that treats each row in the DataFrame as an (index, row) pair. 
                The underscore in the first line means that index is not being used and row is all that matters. We also established the variables "speaker" and "speech" to represent their respective columns.</p>
                <pre><code>
                if speaker not in speakerdictionary:
                    speakerdictionary[speaker] = []
                speakerdictionary[speaker].append(speech)
                </code></pre>
                <p>Here we are checking to see if the speaker already has a speech entry; if it doesn't, we'll create a new empty list to input their speech. Then, whatever speech the loop is currently on gets added to the list.</p>
            </section>
             <section id="step3">
                <h2>Step 3: Tokenizing and Lemmatizing</h2>
                 <p>Now that we've created our dictionary, we're still not done cleaning up our text. We'll use the following chunk of code to clean all the data up:</p>
                 <pre><code>
                     def preprocessing():
                         lemmatizer = WordNetLemmatizer()
                         lemmatizeddictionary = {}
                         punctuation = ['...', '--', '``', "''"]
                         for speaker, speeches in speakerdictionary.items():
                            lemmatizeddictionary[speaker] = []
                            for sentence in speeches:
                                tokens = word_tokenize(str(sentence).lower())
                                tokens = [word for word in tokens if
                                word not in string.punctuation and word not in punctuation and word != 'nan']
                                tokens = [word for word in tokens if not re.fullmatch(r"\s*", word)]
                                filteredtokens = [token for token in tokens if token not in stop_words]

                                lemmatized = [lemmatizer.lemmatize(word) for word in filteredtokens if word]
                                if lemmatized:
                                    lemmatizeddictionary[speaker].append(lemmatized)
                        return lemmatizeddictionary
                 </code></pre>
                 <p>Again, lets look at it in chunks:</p>
                 <pre><code>
                     def preprocessing():
                         lemmatizer = WordNetLemmatizer()
                         lemmatizeddictionary = {}
                         punctuation = ['...', '--', '``', "''"]
                         stop_words = set(stopwords.words('english'))
                 </code></pre>
                 <p>This is a little obvious, but we are initializing a few variables here. The first is the WordNetLemmatizer, an NLTK module. Then, we initialize a lemmatized dictionary; this is where we will store our data for it to be 
                    processed through the sentiment analyzer. And lastly, we are defining some punctuation. The reason we are defining these is because after being placed into the speakerdictionary, there are still some punctuation and other 
                    variables that could cause problems when getting the sentiment scores. We want to look at speech and necessary punctuation only. Thats why it's important to double check by printing your dictionary (though this process may
                    take a minute. Lastly, we are defining our stop words.</p>
                 <pre><code>
                         for speaker, speeches in speakerdictionary.items():
                            lemmatizeddictionary[speaker] = []
                 </code></pre>
                 <p> Here we're initializing an empty list for each speaker before you start filling it with cleaned, tokenized, and lemmatized data.</p>
                 <pre><code>
                             for sentence in speeches:
                                tokens = word_tokenize(str(sentence).lower())
                                tokens = [word for word in tokens if word not in string.punctuation and word not in punctuation and word != 'nan']
                                tokens = [word for word in tokens if not re.fullmatch(r"\s*", word)]
                                filteredtokens = [token for token in tokens if token not in stop_words]

                                lemmatized = [lemmatizer.lemmatize(word) for word in filteredtokens if word]
                                if lemmatized:
                                    lemmatizeddictionary[speaker].append(lemmatized)

                        return lemmatizeddictionary
                 </code></pre>
                 <p>For each of the speeches, we're going in and lowering the text, removing any stop words, the punctuation we defined earlier, and ensuring there are no strings that aren't speech (such as that "nan" above). The remaining words that
                 don't fall into those categories automatically get added to the lemmatized dictionary.</p>
             </section>
            
             <section id="step4">
                 <h2>Step 4: Analyzing Your Data</h2>
                 <p>Our lemmatized dictionary is up and running, which means we can now run it through the analyzer.</p>
                 <pre><code>
                     def sentiment(speakerdictionary):
                        analyzer = SentimentIntensityAnalyzer()
                        for speaker, speeches in speakerdictionary.items():
                            text = " ".join([" ".join(sentence) for sentence in speeches])
                            if not text:
                                continue

                            scores = analyzer.polarity_scores(text)
                            print(f"{speaker}: {scores}")
                 </code></pre>
                 <p>First, we define the sentiment analyzer as the variable "analyzer." Then we'll loop through each speaker and their speeches and rebuilding the sentences. If the list has no text (which it shouldn't) it gets skipped. The scores are then 
                 calculated and printed in a speaker: scores format.</p>
             </section>
            <section id="step5">
                <h2>Step 5: Results</h2>
                <p>Now, finally, we can run the analyzer and get our results. To do this, simply run the following code chunk:</p>
                <pre><code>
                    data = preprocessing()
                    sentiment(data)
                </code></pre>
                <p>This should print the following:</p>
                <pre><code>
                    Elizabeth Warren: {'neg': 0.121, 'neu': 0.686, 'pos': 0.193, 'compound': 1.0}
                    Amy Klobuchar: {'neg': 0.087, 'neu': 0.717, 'pos': 0.196, 'compound': 1.0}
                    Beto O'Rourke: {'neg': 0.126, 'neu': 0.663, 'pos': 0.211, 'compound': 0.9998}
                    Cory Booker: {'neg': 0.153, 'neu': 0.631, 'pos': 0.216, 'compound': 0.9999}
                    Julian Castro: {'neg': 0.083, 'neu': 0.709, 'pos': 0.207, 'compound': 0.9999}
                    Tulsi Gabbard: {'neg': 0.17, 'neu': 0.621, 'pos': 0.209, 'compound': 0.9974}
                    Bill de Blasio: {'neg': 0.123, 'neu': 0.672, 'pos': 0.205, 'compound': 0.999}
                    John Delaney: {'neg': 0.064, 'neu': 0.7, 'pos': 0.236, 'compound': 0.9998}
                    Jay Inslee: {'neg': 0.098, 'neu': 0.639, 'pos': 0.263, 'compound': 0.9997}
                    Tim Ryan: {'neg': 0.091, 'neu': 0.711, 'pos': 0.198, 'compound': 0.9995}
                    Bernie Sanders: {'neg': 0.131, 'neu': 0.677, 'pos': 0.192, 'compound': 1.0}
                    Michael Bennet: {'neg': 0.104, 'neu': 0.701, 'pos': 0.196, 'compound': 0.9993}
                    Joe Biden: {'neg': 0.088, 'neu': 0.774, 'pos': 0.139, 'compound': 1.0}
                    Kamala Harris: {'neg': 0.115, 'neu': 0.681, 'pos': 0.204, 'compound': 0.9999}
                    John Hickenlooper: {'neg': 0.116, 'neu': 0.723, 'pos': 0.161, 'compound': 0.9931}
                    Kirsten Gillibrand: {'neg': 0.133, 'neu': 0.692, 'pos': 0.175, 'compound': 0.995}
                    Pete Buttigieg: {'neg': 0.122, 'neu': 0.697, 'pos': 0.181, 'compound': 1.0}
                    Andrew Yang: {'neg': 0.102, 'neu': 0.692, 'pos': 0.206, 'compound': 1.0}
                    Eric Swalwell: {'neg': 0.197, 'neu': 0.687, 'pos': 0.116, 'compound': -0.993}
                    Marianne Williamson: {'neg': 0.143, 'neu': 0.672, 'pos': 0.185, 'compound': 0.9914}
                    Steve Bullock: {'neg': 0.069, 'neu': 0.734, 'pos': 0.197, 'compound': 0.9992}
                    Tom Steyer: {'neg': 0.126, 'neu': 0.718, 'pos': 0.156, 'compound': 0.999}
                    Mike Bloomberg: {'neg': 0.137, 'neu': 0.713, 'pos': 0.15, 'compound': 0.9628}
                </code></pre>
                <p>We finally have our analysis. To understand what we're looking at, we first need to understand what the numbers mean. Positive, negative, and neutral scores are calculated on a 0 to 1 scale, with 0 being negative and 1 being positive. "Compound" is an overall score of the sentiment of the person's speech, on a -1 to 1 scale, with -1 being very negative, 0 neutral, and 1 very positive.
                Why, perhaps, is Eric Swalwell's sentiment score so low overall? With this sentiment analysis, we can take a deeper dive into each candidate and what they said. </p>
                 
        </main>
        <p>Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.</p>
        <footer>
            <h1>Conclusive Section With Contact Information</h1>
            <p>Last Notes Here:conclusion</p>

            <address>
                Written by<a href="mailto:youremail@example.com"> Kathleen Costa</a>
                
            </address>
        </footer>

    </body>
</html>
